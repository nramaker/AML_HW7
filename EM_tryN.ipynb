{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 unique documents\n",
      "1490 unique words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1480</th>\n",
       "      <th>1481</th>\n",
       "      <th>1482</th>\n",
       "      <th>1483</th>\n",
       "      <th>1484</th>\n",
       "      <th>1485</th>\n",
       "      <th>1486</th>\n",
       "      <th>1487</th>\n",
       "      <th>1488</th>\n",
       "      <th>1489</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...   1480  \\\n",
       "docid                                                              ...          \n",
       "1       1.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  ...    0.1   \n",
       "2       0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  ...    0.1   \n",
       "3       0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  ...    0.1   \n",
       "4       0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  ...    0.1   \n",
       "5       0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  ...    0.1   \n",
       "\n",
       "       1481  1482  1483  1484  1485  1486  1487  1488  1489  \n",
       "docid                                                        \n",
       "1       1.1   0.1   0.1   0.1   4.1  16.1   1.1   4.1   3.1  \n",
       "2       0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  \n",
       "3       0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  \n",
       "4       1.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  \n",
       "5       0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1   0.1  \n",
       "\n",
       "[5 rows x 1490 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nips = pd.read_csv('./NIPS/nips.txt',delimiter=' ')\n",
    "nips = nips.pivot(columns='wordid', index='docid', values='count')\n",
    "nips = nips.fillna(value=0)\n",
    "nips = np.add(nips,0.1)\n",
    "\n",
    "badcols = list(np.flatnonzero(np.sum(nips.values, 1)<1000))\n",
    "allcols = list(range(1,1491))\n",
    "cols = [x for x in allcols if x not in badcols]\n",
    "nips = nips.iloc[:,cols]\n",
    "nips.columns = list(range(0,nips.shape[1]))\n",
    "#nips = nips.add(1)\n",
    "nips_data = nips.values\n",
    "\n",
    "print(str(nips.shape[0]) + \" unique documents\")\n",
    "print(str(nips.shape[1]) + \" unique words\")\n",
    "nips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def e_step(data,mu,k,pi):\n",
    "    \n",
    "    # data is a dxn numpy array of word counts\n",
    "    # mu is a kxd numpy array of cluster centroids\n",
    "    # k is the cluster number\n",
    "    # pi is a kx1 array of cluster membership probabilities\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    d = data.shape[1]\n",
    "    \n",
    "    h1 = np.multiply(data,data)\n",
    "    h1 = np.matmul(h1,np.ones((d,k)))\n",
    "    \n",
    "    h2 = np.matmul(np.ones((n,d)), np.multiply(mu,mu).T)\n",
    "    \n",
    "    h3 = np.matmul(data,mu.T)\n",
    "    \n",
    "    H = -0.5*(np.subtract(np.add(h1,h2),2*h3))\n",
    "    #print(np.mean(H))\n",
    "\n",
    "    P = np.matmul(np.ones((n,1)),pi.T)\n",
    "    #print(np.mean(P))\n",
    "    \n",
    "    E = np.multiply(np.exp(H),P)\n",
    "    F = np.matmul(E,np.ones((k,k)))\n",
    "    F = np.add(F,0.01)\n",
    "    W = np.divide(E,F)\n",
    "    return(W)\n",
    "\n",
    "\n",
    "def m_step(W,data):\n",
    "    # W is a nxk array of document likelihoods (given cluster)\n",
    "    # data is a dxn array of word counts\n",
    "    n = data.shape[0]\n",
    "    d = data.shape[1]\n",
    "    \n",
    "    D = np.matmul(W.T,data)\n",
    "    G = np.matmul(W.T,np.ones((n,d)))\n",
    "    mu_new = np.divide(D,G)\n",
    "    return(mu_new)\n",
    "\n",
    "def m_step_log(W,data,pis,alpha):\n",
    "    n = data.shape[0]\n",
    "    d = data.shape[1]\n",
    "    pi_new = np.log(np.matmul(W.T,np.ones((n,1))))\n",
    "    pi_new = np.subtract(pi_new, np.log(n))\n",
    "    W = np.multiply(alpha,W)\n",
    "    mu_new = np.matmul(W.T,data)\n",
    "    mu_new = np.divide(mu_new,np.matmul(W.T,np.ones((n,d))))\n",
    "    return(mu_new)\n",
    "    \n",
    "def evalulate(mu_old,mu_new,threshold):\n",
    "    diff = np.subtract(mu_new,mu_old)\n",
    "    if np.linalg.norm(diff) <= threshold:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.085839084001476e-79\n",
      "0.10021891387010154\n",
      "0.10021891387010154\n"
     ]
    }
   ],
   "source": [
    "## Initialize\n",
    "k = 3\n",
    "d = nips_data.shape[1]\n",
    "n = nips_data.shape[0]\n",
    "topic_centers = np.random.random(k)\n",
    "mu = topic_centers.reshape((k,1))\n",
    "mus = np.random.random(k*d)\n",
    "mus = mus.reshape((k,d))\n",
    "pi = np.ones((k,1))*1/k\n",
    "\n",
    "counter = 1\n",
    "#while counter<10:\n",
    "W = e_step(data=nips_data,k=3,mu=mus,pi=pi)\n",
    "\n",
    "#inspect the weights we got back\n",
    "print(\"Each of these number should be between 0 and 1500 (#number of documents)\")\n",
    "print(\"When all summed together, they sholuld be roughly 1500\")\n",
    "print(\"sum of document weights to first topic:\", sum(W.T[0]))\n",
    "print(\"sum of document weights to second topic:\", sum(W.T[1]))\n",
    "print(\"sum of document weights to third topic:\", sum(W.T[2]))\n",
    "print(np.mean(W))\n",
    "\n",
    "mu_new = m_step(data=nips_data,W=W)\n",
    "print(np.mean(mu_new))\n",
    "mu_new = m_step_log(data=nips_data,W=W,pis=pi,alpha=10)\n",
    "print(np.mean(mu_new))\n",
    "\n",
    "#print(\"Iteration \" + str(counter))\n",
    "#print(np.mean(mu_new))\n",
    "#counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
